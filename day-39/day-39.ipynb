{
 "cells": [
  {
   "cell_type": "code",
   "id": "5cb1718763d602b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.173254Z",
     "start_time": "2025-12-02T08:31:11.164959Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from time import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import re\n",
    "import evidently\n",
    "from evidently import Report\n",
    "from evidently.presets.classification import ClassificationPreset\n",
    "from evidently.presets.drift import DataDriftPreset\n",
    "import pandas as pd\n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently import MulticlassClassification"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "id": "ac6d67efdd411df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.228193Z",
     "start_time": "2025-12-02T08:31:11.221507Z"
    }
   },
   "source": [
    "#last class er MyABSAService file tar directory ta copy kore nisi to load the model_weights.pth and vocab.pkl files\n",
    "ROOT_DIR = r'C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\MyABSAService'"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "id": "e7a11ad2c451ba60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.243238Z",
     "start_time": "2025-12-02T08:31:11.237505Z"
    }
   },
   "source": [
    "dictionary_path = ROOT_DIR + r'\\vocab.pkl'\n",
    "model_path = ROOT_DIR + r'\\model_weights.pth'"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "10a6c2f19b63206e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.261745Z",
     "start_time": "2025-12-02T08:31:11.251835Z"
    }
   },
   "source": [
    "token_2_id=None\n",
    "with open(ROOT_DIR + r'\\vocab.pkl', \"rb\") as f:\n",
    "    token_2_id = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "id": "6a9aa87a1c384c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.276131Z",
     "start_time": "2025-12-02T08:31:11.270067Z"
    }
   },
   "source": [
    "# Normalize\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "id": "4eca20102c04c3f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.290017Z",
     "start_time": "2025-12-02T08:31:11.284940Z"
    }
   },
   "source": [
    "# Tokenize\n",
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "id": "2ade5e15e52f54a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.309128Z",
     "start_time": "2025-12-02T08:31:11.302654Z"
    }
   },
   "source": [
    "# Convert tokens into ids\n",
    "def convert_tokens_2_ids(tokens):\n",
    "    input_ids = [\n",
    "        token_2_id.get(token, token_2_id['<UNK>']) for token in tokens\n",
    "    ]\n",
    "    return input_ids"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "id": "ba6b181ae2dc02eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.331938Z",
     "start_time": "2025-12-02T08:31:11.322938Z"
    }
   },
   "source": [
    "# Process an input text\n",
    "def process_text(text, aspect):\n",
    "    text_aspect_pair = text + ' ' + aspect\n",
    "    normalized_text = normalize(text_aspect_pair)\n",
    "    tokens = tokenize(normalized_text)\n",
    "    input_ids = convert_tokens_2_ids(tokens)\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "    return input_ids"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "id": "5f7015351d8808ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.461315Z",
     "start_time": "2025-12-02T08:31:11.351970Z"
    }
   },
   "source": [
    "# ABSA Model\n",
    "class ABSA(nn.Module):\n",
    "    def __init__(self, vocab_size, num_labels=3):\n",
    "        super(ABSA, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_labels = num_labels\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=256\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=512,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Linear(\n",
    "            in_features=512,\n",
    "            out_features=self.num_labels\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm_layer(embeddings)\n",
    "        logits = self.fc_layer(lstm_out[:, -1, :])\n",
    "        return logits\n",
    "\n",
    "model = ABSA(\n",
    "    vocab_size=len(token_2_id.keys()),\n",
    "    num_labels=3\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)\n",
    ")\n",
    "model.eval()\n",
    "print(\"Model loaded successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "id": "78d37d55b9093071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.523429Z",
     "start_time": "2025-12-02T08:31:11.503072Z"
    }
   },
   "source": [
    "SENTIMENT_LABELS={\n",
    "            0: 'negative',\n",
    "            1: 'neutral',\n",
    "            2: 'positive',\n",
    "        }\n",
    "def log_prediction(text, aspect, sentiment, label, confidence, inference_time):\n",
    "    metrics = pd.read_csv(\n",
    "        ROOT_DIR + r'\\inference_metric.csv',\n",
    "\n",
    "    )\n",
    "    new_row = {\n",
    "        'timestamp': pd.Timestamp.now(),#returns the current date and time (timestamp) of your system.\n",
    "        'text': text,\n",
    "        'aspect': aspect,\n",
    "        'sentiment': sentiment, # Negative, Neutral, Positive\n",
    "        'target': \"\",\n",
    "        'prediction': label, # 0, 1, 2\n",
    "        'confidence': confidence, # probability [0.15, 0.65, 0.20]\n",
    "        'inference_time': inference_time,\n",
    "    }\n",
    "    metrics = pd.concat(\n",
    "        [metrics, pd.DataFrame([new_row])],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        metrics.to_csv(ROOT_DIR + r'\\inference_metric.csv', index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "def predict_sentiment(text, aspect):\n",
    "    start_time = time()\n",
    "    input_ids = process_text(text, aspect)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids)\n",
    "        inference_time = time() - start_time#How long the model takes to make a prediction for one input.\n",
    "        probs=torch.softmax(logits, dim=-1)#[0.1,0.5,0.6]\n",
    "        label=probs.argmax(dim=-1).item()#[0.6 ]\n",
    "        sentiment =SENTIMENT_LABELS[label]\n",
    "        confidence=probs.squeeze().tolist()[label]\n",
    "\n",
    "        log_prediction(text, aspect, sentiment, label, confidence, inference_time)\n",
    "        return {\"sentiment\":sentiment, \"confidence\":confidence}\n"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "id": "ce7a9784c7363258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:11.559370Z",
     "start_time": "2025-12-02T08:31:11.545699Z"
    }
   },
   "source": [
    "batch=[\n",
    "    {\"input_ids\": [5, 7, 9], \"label\": 1},\n",
    "    {\"input_ids\": [4, 3], \"label\": 0},\n",
    "    {\"input_ids\": [10, 11, 12, 13], \"label\": 1}\n",
    "]\n",
    "\n",
    "batch_input_ids = [item['input_ids'] for item in batch]\n",
    "batch_labels = [item['label'] for item in batch]\n",
    "print(batch_input_ids)\n",
    "print(batch_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 7, 9], [4, 3], [10, 11, 12, 13]]\n",
      "[1, 0, 1]\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "id": "cb52fc3b63039020",
   "metadata": {},
   "source": [
    "# **Model Monitoring**"
   ]
  },
  {
   "cell_type": "code",
   "id": "24bbf95688594694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:26:31.113945Z",
     "start_time": "2025-12-02T09:26:31.069593Z"
    }
   },
   "source": [
    "reference_df=pd.read_csv(ROOT_DIR+r'\\reference_data.csv')\n",
    "current_df=pd.read_csv(ROOT_DIR+r'\\inference_metric.csv')\n",
    "reference_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  timestamp                                               text    aspect  \\\n",
       "0   49:34.9  The food was great but the service was terribl...      food   \n",
       "1   49:35.0  The food was great but the service was terribl...   service   \n",
       "2   49:35.0  The food was great but the service was terribl...  ambience   \n",
       "\n",
       "  sentiment  target  prediction  confidence  inference_time  \n",
       "0   neutral       1           1    0.840034        0.062681  \n",
       "1  negative       0           0    0.850334        0.002503  \n",
       "2  positive       2           2    0.860276        0.003001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49:34.9</td>\n",
       "      <td>The food was great but the service was terribl...</td>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840034</td>\n",
       "      <td>0.062681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49:35.0</td>\n",
       "      <td>The food was great but the service was terribl...</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850334</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49:35.0</td>\n",
       "      <td>The food was great but the service was terribl...</td>\n",
       "      <td>ambience</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860276</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "id": "fbd92a55ed2280ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:26:39.742261Z",
     "start_time": "2025-12-02T09:26:39.730698Z"
    }
   },
   "source": [
    "columns=[\"target\",\"prediction\"]#only jei column gulo monitor korte cai\n",
    "reference_df=reference_df[columns]\n",
    "current_df=current_df[columns]\n",
    "current_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    target  prediction\n",
       "0        2           2\n",
       "1        2           2\n",
       "2        1           2\n",
       "3        2           2\n",
       "4        2           2\n",
       "5        2           1\n",
       "6        2           2\n",
       "7        0           2\n",
       "8        2           2\n",
       "9        2           1\n",
       "10       2           2\n",
       "11       2           2\n",
       "12       2           0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ekta problem hocche amdr model ta always predicion hisebe always positive predict kore jar karone evidently onk error show kore...sei jonno ekhane ami manually csv file ta te predicion column e kichu change korsi to to see the report",
   "id": "a9c6355146561ff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:27:06.931569Z",
     "start_time": "2025-12-02T09:27:06.917689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data for monitoring\n",
    "reference_data = Dataset.from_pandas(\n",
    "    reference_df,\n",
    "    data_definition=DataDefinition(  classification=[\n",
    "        MulticlassClassification(\n",
    "            target=\"target\",\n",
    "            prediction_labels=\"prediction\"\n",
    "        )\n",
    "    ]),\n",
    ")\n",
    "current_data = Dataset.from_pandas(\n",
    "    current_df,\n",
    "    data_definition=DataDefinition(  classification=[\n",
    "        MulticlassClassification(\n",
    "            target=\"target\",\n",
    "            prediction_labels=\"prediction\"\n",
    "        )\n",
    "    ]),\n",
    ")\n"
   ],
   "id": "fdfa2417b689b4fb",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:27:08.225365Z",
     "start_time": "2025-12-02T09:27:08.046761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Performance Report\n",
    "classification_report = Report(\n",
    "    metrics=[ClassificationPreset()],\n",
    "    include_tests=True,\n",
    ")\n",
    "\n",
    "classification_result = classification_report.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data,\n",
    ")\n",
    "\n",
    "classification_result.save_html(ROOT_DIR + r\"\\classification_report.html\")"
   ],
   "id": "3bf11eafbac020b8",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:27:11.595263Z",
     "start_time": "2025-12-02T09:27:11.485855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataDrift Report #means datar distribution e kono change asche kina check kora.jemon training er somoy \"poisitve,negative,neutral\" ei 3 ta sentmient er j distribution chilo sei distribution ta  inference er somoy change hoise kina seta check korar dorkar ase\n",
    "drift_report=Report(\n",
    "    metrics=[DataDriftPreset()]\n",
    "\n",
    ")\n",
    "# Create DataDrift Report\n",
    "drift_report = Report(\n",
    "    metrics=[DataDriftPreset()])\n",
    "\n",
    "datadrift_result = drift_report.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data,\n",
    ")\n",
    "datadrift_result.save_html(ROOT_DIR + r\"\\drift_report.html\")\n"
   ],
   "id": "b499e0633e156dce",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T08:31:16.941782Z",
     "start_time": "2025-12-02T08:31:16.938189Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ca9be5808b80a431",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
