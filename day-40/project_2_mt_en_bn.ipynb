{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "executionInfo": {
     "status": "error",
     "timestamp": 1757400199832,
     "user_tz": -360,
     "elapsed": 136,
     "user": {
      "displayName": "KARABI KUMARI MEDHA 1604062",
      "userId": "02676772162340716864"
     }
    },
    "outputId": "4ca67866-ac7a-4f35-9d5f-11d09460a5ef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "ExecuteTime": {
     "end_time": "2025-12-05T09:13:36.275570Z",
     "start_time": "2025-12-05T09:11:59.169374Z"
    }
   },
   "source": [
    "from typing import Any\n",
    "\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "\n",
    "\"\"\" Class 25 | Project 2 | Machine Translation using Pretrained Model\n",
    "\n",
    "Objectives:\n",
    "1. End-to-end machine translation training pipeline\n",
    "2. Fine-tune a pre-trained model for the custom dataset\n",
    "\"\"\"\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchmetrics.text import BLEUScore\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "cd6712aad1b548d7",
    "outputId": "824c43b6-2d5e-480e-da6d-35338820f1fe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187729883,
     "user_tz": -360,
     "elapsed": 187,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-05T09:13:36.388473Z",
     "start_time": "2025-12-05T09:13:36.377798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "cd6712aad1b548d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "eaa67c3f07ec30e2",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:30.297390Z",
     "start_time": "2025-12-05T09:14:30.293530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Task: English to Bangla \"\"\"\n",
    "\n",
    "mt_pretrained_model_name = \"shhossain/opus-mt-en-to-bn\""
   ],
   "id": "eaa67c3f07ec30e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "a0d805fe4a8ab875",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187729919,
     "user_tz": -360,
     "elapsed": 18,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    },
    "outputId": "cae2f309-54cf-49f1-dee7-786aedc7622d",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:35.905601Z",
     "start_time": "2025-12-05T09:14:31.080767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" For NLP tasks, we basically need two entities:\n",
    "1. Tokenizer\n",
    "2. Model\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(mt_pretrained_model_name)\n",
    "mt_pretrained_model = AutoModelForSeq2SeqLM.from_pretrained(mt_pretrained_model_name)"
   ],
   "id": "a0d805fe4a8ab875",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:07:06.824724Z",
     "start_time": "2025-12-02T17:07:06.816253Z"
    }
   },
   "cell_type": "code",
   "source": "print(mt_pretrained_model.forward) #downloded model e ki ki layer ase seta check kortesi",
   "id": "74f28987a7f11119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method MarianMTModel.forward of MarianMTModel(\n",
      "  (model): MarianModel(\n",
      "    (shared): Embedding(61760, 512, padding_idx=61759)\n",
      "    (encoder): MarianEncoder(\n",
      "      (embed_tokens): Embedding(61760, 512, padding_idx=61759)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianEncoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): SiLU()\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): MarianDecoder(\n",
      "      (embed_tokens): Embedding(61760, 512, padding_idx=61759)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianDecoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (activation_fn): SiLU()\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=61760, bias=False)\n",
      ")>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:19:18.154782Z",
     "start_time": "2025-12-02T17:19:18.145779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "print(inspect.signature(mt_pretrained_model.forward))# downloaded model er input parameter ki ki ase seta dekhtesi\n"
   ],
   "id": "c62aa36c22ced475",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(input_ids: Optional[torch.LongTensor] = None, attention_mask: Optional[torch.Tensor] = None, decoder_input_ids: Optional[torch.LongTensor] = None, decoder_attention_mask: Optional[torch.Tensor] = None, head_mask: Optional[torch.Tensor] = None, decoder_head_mask: Optional[torch.Tensor] = None, cross_attn_head_mask: Optional[torch.Tensor] = None, encoder_outputs: Union[tuple[torch.Tensor], transformers.modeling_outputs.BaseModelOutput, NoneType] = None, past_key_values: Optional[transformers.cache_utils.Cache] = None, inputs_embeds: Optional[torch.FloatTensor] = None, decoder_inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.LongTensor] = None, use_cache: Optional[bool] = None, output_attentions: Optional[bool] = None, output_hidden_states: Optional[bool] = None, return_dict: Optional[bool] = None, cache_position: Optional[torch.Tensor] = None) -> transformers.modeling_outputs.Seq2SeqLMOutput\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:59:47.804663Z",
     "start_time": "2025-12-02T17:59:47.749324Z"
    }
   },
   "cell_type": "code",
   "source": "mt_pretrained_model.prepare_inputs_for_generation()",
   "id": "f04904e43f3e0e9e",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GenerationMixin.prepare_inputs_for_generation() missing 1 required positional argument: 'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmt_pretrained_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprepare_inputs_for_generation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: GenerationMixin.prepare_inputs_for_generation() missing 1 required positional argument: 'input_ids'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T19:53:37.854683Z",
     "start_time": "2025-12-02T19:53:37.817956Z"
    }
   },
   "cell_type": "code",
   "source": "mt_pretrained_model.config",
   "id": "82bff4738462c9d2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mt_pretrained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmt_pretrained_model\u001B[49m.config\n",
      "\u001B[31mNameError\u001B[39m: name 'mt_pretrained_model' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "e93068cfc700f5f8"
   },
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "id": "e93068cfc700f5f8"
  },
  {
   "metadata": {
    "id": "89449c4bacc42140",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187730045,
     "user_tz": -360,
     "elapsed": 29,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    },
    "outputId": "a4dc0573-6e6d-4908-ac0f-8813ed1dc901",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:42.383633Z",
     "start_time": "2025-12-05T09:14:42.372294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Sentence: How are you, dude?\n",
    "Tokens: 'How', 'are', 'you', 'dude?'\n",
    "ids: 125, 14, 145, 78\n",
    "max_length = 3\n",
    "ids: [125, 14, 145]\n",
    "\"\"\"\n",
    "\n",
    "class MTDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = str(self.data.iloc[idx]['en'])\n",
    "        tgt_text = str(self.data.iloc[idx]['bn'])\n",
    "\n",
    "        src_encoding = tokenizer(\n",
    "            src_text,\n",
    "            max_length=128,\n",
    "            padding='max_length',#max length theke choto hole 0 diye padding kore dibe\n",
    "            truncation=True,# maximum length theke boro hole kete dibe\n",
    "            return_tensors='pt',# pytorch er tensor datatype hisebe return korbe\n",
    "        )\n",
    "\n",
    "        tgt_encoding = tokenizer(\n",
    "            tgt_text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'src_input_ids': src_encoding['input_ids'].squeeze(),\n",
    "            'src_attention_mask': src_encoding['attention_mask'].squeeze(),\n",
    "            'tgt_input_ids': tgt_encoding['input_ids'].squeeze(),\n",
    "            'tgt_attention_mask': tgt_encoding['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "example: How are you, dude?\n",
    "input_ids: 125, 14, 145, 78\n",
    "max_length = 7\n",
    "input_ids: [125, 14, 145, 147, 0, 0, 0]\n",
    "attention_mask: [1, 1, 1, 1, 0, 0, 0] #jei value gula te 1 thake segulo hocce real token ar jegulate o thake segulo hocche padded token\n",
    "\"\"\""
   ],
   "id": "89449c4bacc42140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexample: How are you, dude?\\ninput_ids: 125, 14, 145, 78\\nmax_length = 7\\ninput_ids: [125, 14, 145, 147, 0, 0, 0]\\nattention_mask: [1, 1, 1, 1, 0, 0, 0] #jei value gula te 1 thake segulo hocce real token ar jegulate o thake segulo hocche padded token\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "7dec7cfe5693f5f1",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:44.065313Z",
     "start_time": "2025-12-05T09:14:44.053123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_csv, val_csv, test_csv, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_csv = train_csv\n",
    "        self.val_csv = val_csv\n",
    "        self.test_csv = test_csv\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):#sobar age ei setup ta call hoy\n",
    "        self.train_dataset = MTDataset(self.train_csv)\n",
    "        self.val_dataset = MTDataset(self.val_csv)\n",
    "        self.test_dataset = MTDataset(self.test_csv)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )"
   ],
   "id": "7dec7cfe5693f5f1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "ef2deed7494ec4b4",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:21:42.435549Z",
     "start_time": "2025-12-05T09:21:42.427500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_module = MTDataModule(\n",
    "    train_csv=r'train.csv',\n",
    "    val_csv=r'val.csv',\n",
    "    test_csv=r'test.csv',\n",
    "    batch_size=32\n",
    ")"
   ],
   "id": "ef2deed7494ec4b4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "id": "86e90bfb5b63dafe"
   },
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "id": "86e90bfb5b63dafe"
  },
  {
   "metadata": {
    "id": "70ac9ff9786267a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187730281,
     "user_tz": -360,
     "elapsed": 204,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    },
    "outputId": "7a8e4dc0-2b1e-46ec-8c32-cef34f48ee96",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:48.484910Z",
     "start_time": "2025-12-05T09:14:48.473336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # load pretrained model\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(mt_pretrained_model_name)\n",
    "        # load pretrained tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(mt_pretrained_model_name)\n",
    "        # learning rate\n",
    "        self.learning_rate = 2e-5\n",
    "        # loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss(\n",
    "            ignore_index=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # evaluation metric\n",
    "        self.bleu = BLEUScore()#machine translation ta koto valo kaj kore seta check korar jonnno use kora hoy BLEUScore.jemon classification er jonno use kora hoy accuracy\n",
    "\n",
    "    def forward(self,\n",
    "                src_input_ids,\n",
    "                src_attention_mask,\n",
    "                tgt_input_ids,\n",
    "                tgt_attention_mask\n",
    "        ):\n",
    "        outputs = self.model(\n",
    "            input_ids=src_input_ids,\n",
    "            attention_mask=src_attention_mask,\n",
    "            decoder_input_ids=tgt_input_ids[:, :-1],\n",
    "            decoder_attention_mask=tgt_attention_mask[:, :-1]\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx, 'train')\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx, 'val')\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx, 'test')\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=10\n",
    "        )\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    def compute_loss(self, batch, batch_idx, stage):\n",
    "        src_input_ids = batch['src_input_ids']\n",
    "        src_attention_mask = batch['src_attention_mask']\n",
    "        tgt_input_ids = batch['tgt_input_ids']\n",
    "        tgt_attention_mask = batch['tgt_attention_mask']\n",
    "\n",
    "        outputs = self(\n",
    "            src_input_ids,\n",
    "            src_attention_mask,\n",
    "            tgt_input_ids,\n",
    "            tgt_attention_mask\n",
    "        )\n",
    "        \"\"\"CrossEntropy needs input shape(N,C) where N=number of tokens=number of batch*number of tokens in each batch\"\"\"\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fn(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            tgt_input_ids[:, 1:].contiguous().view(-1)\n",
    "        )\n",
    "\n",
    "        if stage == 'val' or stage == 'test':\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            pred_texts = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "            tgt_texts = self.tokenizer.batch_decode(tgt_input_ids[:, 1:], skip_special_tokens=True)\n",
    "            bleu_score = self.bleu(pred_texts, [[tgt] for tgt in tgt_texts])\n",
    "            self.log(f'{stage}_bleu', bleu_score, prog_bar=True)\n",
    "\n",
    "        return loss\n"
   ],
   "id": "70ac9ff9786267a5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "76dccd8fe08376a4",
    "ExecuteTime": {
     "end_time": "2025-12-05T09:14:54.015770Z",
     "start_time": "2025-12-05T09:14:51.196416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MTModel()"
   ],
   "id": "76dccd8fe08376a4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "c037b19d321b93ff"
   },
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "id": "c037b19d321b93ff"
  },
  {
   "metadata": {
    "id": "1bd38416398d770a",
    "ExecuteTime": {
     "end_time": "2025-12-06T11:51:42.968655Z",
     "start_time": "2025-12-06T11:51:42.879557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    precision=16,\n",
    "    log_every_n_steps=10,\n",
    "    val_check_interval=0.25\n",
    ")"
   ],
   "id": "1bd38416398d770a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m trainer = \u001B[43mpl\u001B[49m.Trainer(\n\u001B[32m      2\u001B[39m     max_epochs=\u001B[32m2\u001B[39m,\n\u001B[32m      3\u001B[39m     accelerator=\u001B[33m'\u001B[39m\u001B[33mgpu\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      4\u001B[39m     devices=\u001B[32m1\u001B[39m,\n\u001B[32m      5\u001B[39m     precision=\u001B[32m16\u001B[39m,\n\u001B[32m      6\u001B[39m     log_every_n_steps=\u001B[32m10\u001B[39m,\n\u001B[32m      7\u001B[39m     val_check_interval=\u001B[32m0.25\u001B[39m\n\u001B[32m      8\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'pl' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "add377254e158c86",
    "ExecuteTime": {
     "start_time": "2025-12-05T09:21:50.080984Z"
    }
   },
   "cell_type": "code",
   "source": "# trainer.fit(model, data_module)",
   "id": "add377254e158c86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:242: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType            \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mFLOPs\u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ model   │ MarianMTModel    │ 76.3 M │ eval  │     0 │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ CrossEntropyLoss │      0 │ train │     0 │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ bleu    │ BLEUScore        │      0 │ train │     0 │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model   │ MarianMTModel    │ 76.3 M │ eval  │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ CrossEntropyLoss │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ bleu    │ BLEUScore        │      0 │ train │     0 │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 75.8 M                                                                                           \n",
       "\u001B[1mNon-trainable params\u001B[0m: 524 K                                                                                        \n",
       "\u001B[1mTotal params\u001B[0m: 76.3 M                                                                                               \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 305                                                                        \n",
       "\u001B[1mModules in train mode\u001B[0m: 2                                                                                           \n",
       "\u001B[1mModules in eval mode\u001B[0m: 178                                                                                          \n",
       "\u001B[1mTotal FLOPs\u001B[0m: 0                                                                                                     \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 75.8 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 524 K                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 76.3 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 305                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 2                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 178                                                                                          \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' \n",
       "does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` \n",
       "to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' \n",
       "does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` \n",
       "to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:534: Found 178 module(s) in eval mode at the \n",
       "start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore \n",
       "this warning.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:534: Found 178 module(s) in eval mode at the \n",
       "start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore \n",
       "this warning.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "652b3f73247ae77c",
    "ExecuteTime": {
     "end_time": "2025-12-06T11:51:10.321664Z",
     "start_time": "2025-12-06T11:51:08.319168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.test(model, data_module)"
   ],
   "id": "652b3f73247ae77c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m.test(model, data_module)\n",
      "\u001B[31mNameError\u001B[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:45:33.783106Z",
     "start_time": "2025-04-12T15:45:33.772054Z"
    },
    "id": "9f115c718388b7f9",
    "outputId": "2e3186ce-b52e-4344-cfd5-8fea0ee7b28a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187730430,
     "user_tz": -360,
     "elapsed": 104,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    }
   },
   "cell_type": "code",
   "source": [
    "model.model.config"
   ],
   "id": "9f115c718388b7f9",
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-1573131073.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:47:53.667634Z",
     "start_time": "2025-04-12T15:47:53.659903Z"
    },
    "id": "4db952c7f44ec3b2",
    "outputId": "1c8af67a-9c64-4017-c39b-5bf773a0e8ad",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1757187730464,
     "user_tz": -360,
     "elapsed": 20,
     "user": {
      "displayName": "Chironjit Banerjee",
      "userId": "04428016465669976257"
     }
    }
   },
   "cell_type": "code",
   "source": [
    "for name, module in model.model.named_modules():\n",
    "    print(name)"
   ],
   "id": "4db952c7f44ec3b2",
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-1717071471.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_modules\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
