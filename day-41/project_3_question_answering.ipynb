{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:11:48.375991Z",
     "start_time": "2025-12-10T06:10:30.644885Z"
    }
   },
   "source": [
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler\n",
    "\n",
    "\"\"\"Class 27: Project 3: Question Answering\"\"\"\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForQuestionAnswering,BertTokenizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "82d99bc39661f4df",
    "outputId": "d7d3bdaa-66aa-4f9a-d40a-a7d82de632bc",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:13.003379Z",
     "start_time": "2025-12-10T06:13:12.990478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "82d99bc39661f4df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "train_df=pd.read_csv(\"qna_train.csv\")\n",
    "train_df.head()"
   ],
   "metadata": {
    "id": "PgKVn32dvXe5",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:14.436313Z",
     "start_time": "2025-12-10T06:13:13.721760Z"
    }
   },
   "id": "PgKVn32dvXe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:27:23.972605Z",
     "start_time": "2025-12-10T07:27:23.931416Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(train_df))",
   "id": "4ad2d730b37ac15d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:16:08.225825Z",
     "start_time": "2025-12-10T07:16:07.892186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df=pd.read_csv(\"qna_test.csv\")\n",
    "print(len(test_df))"
   ],
   "id": "4355f66a3949fd3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:18:32.848962Z",
     "start_time": "2025-12-09T12:18:32.842758Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": "train_df['context'][0]",
   "id": "c7bcb2fc5b1cef56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:19:17.048996Z",
     "start_time": "2025-12-09T12:19:17.042055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answers=train_df.iloc[0]['answers']\n",
    "answers\n"
   ],
   "id": "5216ecf84812b766",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:21:12.931450Z",
     "start_time": "2025-12-09T12:21:12.925916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answers=eval(answers)\n",
    "print(answers)"
   ],
   "id": "75573b6e43888cdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **How to use a pretrained model for hugging face**",
   "id": "66674c30485f4e0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:35.218639Z",
     "start_time": "2025-12-10T06:13:25.604725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForQuestionAnswering,AutoTokenizer,pipeline\n",
    "model_name=\"deepset/tinyroberta-squad2\"\n",
    "quesiton_answer=pipeline(\n",
    "    task=\"question-answering\",#means ki dhoroner task er jonno amra eta toiri kortesi.ei name ta ami banay deinai.ekhane task er name ta evabei dite hobe\n",
    "    model=model_name,\n",
    "    tokenizer=model_name#all NLP related task e tokenizer er proyojon hoy\n",
    "\n",
    ")\n"
   ],
   "id": "97d11489db5a9306",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:41.156583Z",
     "start_time": "2025-12-10T06:13:41.150555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input={\n",
    "    'question':'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
    "    'context':'Architecturally, the school has a Catholic character. Atop the Main Buildings gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend Venite Ad Me Omnes. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'\n",
    "}"
   ],
   "id": "342dd0d8d1deba83",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:42.488534Z",
     "start_time": "2025-12-10T06:13:41.690128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output=quesiton_answer(input)\n",
    "print(output)"
   ],
   "id": "57baf30a5177494f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9906218047835864, 'start': 512, 'end': 538, 'answer': 'Saint Bernadette Soubirous'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:45.695956Z",
     "start_time": "2025-12-10T06:13:45.687056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx=0\n",
    "context=train_df.iloc[idx]['context']\n",
    "question=train_df.iloc[idx]['question']\n",
    "answers=train_df.iloc[idx]['answers']\n",
    "answer_start=eval(train_df.iloc[idx]['answers'])['answer_start']\n",
    "print(question)\n",
    "print(answers)\n",
    "print(answer_start)"
   ],
   "id": "f87f5d19cef6925a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n",
      "[515]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:47.604153Z",
     "start_time": "2025-12-10T06:13:46.460262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "tokens = tokenizer.encode_plus(\n",
    "                context,\n",
    "                question,\n",
    "                add_special_tokens=True,\n",
    "                max_length=16,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt',\n",
    "                return_offsets_mapping=True\n",
    "            )\n"
   ],
   "id": "4de9ad94ededf788",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:50.928855Z",
     "start_time": "2025-12-10T06:13:50.921688Z"
    }
   },
   "cell_type": "code",
   "source": "tokens['attention_mask']",
   "id": "89bf08d9df76f136",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:13:52.069452Z",
     "start_time": "2025-12-10T06:13:52.063134Z"
    }
   },
   "cell_type": "code",
   "source": "tokens['input_ids']",
   "id": "76122387f4449894",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 37848, 37471, 28108,     6,     5,   334,     2,     2,  3972,\n",
       "          2661,   222,     5,  9880,  2708,     2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "d022405d37e92a01"
   },
   "cell_type": "markdown",
   "source": "# Data",
   "id": "6b47ec5b6d0f0c64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:15:21.876994Z",
     "start_time": "2025-12-10T06:15:21.856349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QnADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.df.iloc[idx]['context']\n",
    "        question = self.df.iloc[idx]['question']\n",
    "        answers = eval(self.df.iloc[idx]['answers'])['text'][0]\n",
    "        answer_start = eval(self.df.iloc[idx]['answers'])['answer_start'][0]\n",
    "\n",
    "        try:\n",
    "            tokens = self.tokenizer.encode_plus(\n",
    "                context,\n",
    "                question,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt',\n",
    "                return_offsets_mapping=True,\n",
    "            )\n",
    "            \"\"\"Tokenizer breaks your text into pieces â†’ offset mapping tells you where each token came from in the original string.\n",
    "            Tokens:[\"Hello\", \"world\"]\n",
    "            offset_mapping:[(0, 5), (6, 11)]\n",
    "tokens: ['Hugging', 'Face', 'is', 'amazing']\n",
    "\n",
    "offset_mapping:\n",
    "[(0, 7), (7, 11), (12, 14), (15, 22)]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            tokens = {\n",
    "                'input_ids': torch.zeros(512, dtype=torch.long),\n",
    "                'attention_mask': torch.zeros(512, dtype=torch.long),\n",
    "                'offset_mapping': torch.zeros((512, 2), dtype=torch.long),\n",
    "            }\n",
    "\n",
    "        input_ids = tokens['input_ids'].squeeze()\n",
    "        attention_mask = tokens['attention_mask'].squeeze()\n",
    "        offset_mapping = tokens['offset_mapping'].squeeze()\n",
    "\n",
    "        start_position = 0\n",
    "        end_position = 0\n",
    "        answer_end = answer_start + len(answers)\n",
    "\n",
    "        for i, (start_char, end_char) in enumerate(offset_mapping):\n",
    "            if start_char <= answer_start < end_char:\n",
    "                start_position = i\n",
    "            if start_char < answer_end <= end_char:\n",
    "                end_position = i\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'start_positions': torch.tensor([start_position], dtype=torch.long),\n",
    "            'end_positions': torch.tensor([end_position], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "class QnADataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data_path, test_data_path, tokenizer):\n",
    "        super().__init__()\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(self.train_data_path)\n",
    "        # train_df = train_df.sample(n=10000, random_state=42, replace=False)\n",
    "\n",
    "        test_df = pd.read_csv(self.test_data_path)\n",
    "        # test_df = test_df.sample(n=2000, random_state=42, replace=False)\n",
    "\n",
    "        self.train_ds = QnADataset(train_df, self.tokenizer)\n",
    "        self.test_ds = QnADataset(test_df, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=4,\n",
    "            shuffle=False,\n",
    "        )"
   ],
   "id": "d9d2acc7768de455",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "id": "f3b11f5587c78dae",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:52:01.760406Z",
     "start_time": "2025-12-10T06:52:01.611213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QnADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.df.iloc[idx]['context']\n",
    "        question = self.df.iloc[idx]['question']\n",
    "        answers = eval(self.df.iloc[idx]['answers'])['text'][0]\n",
    "        answer_start = eval(self.df.iloc[idx]['answers'])['answer_start'][0]\n",
    "\n",
    "        try:\n",
    "            tokens = self.tokenizer.encode_plus(\n",
    "                context,\n",
    "                question,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt',\n",
    "                return_offsets_mapping=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            tokens = {\n",
    "                'input_ids': torch.zeros(512, dtype=torch.long),\n",
    "                'attention_mask': torch.zeros(512, dtype=torch.long),\n",
    "                'offset_mapping': torch.zeros((512, 2), dtype=torch.long),\n",
    "            }\n",
    "\n",
    "        input_ids = tokens['input_ids'].squeeze()\n",
    "        attention_mask = tokens['attention_mask'].squeeze()\n",
    "        offset_mapping = tokens['offset_mapping'].squeeze()\n",
    "\n",
    "        start_position = 0\n",
    "        end_position = 0\n",
    "        answer_end = answer_start + len(answers)\n",
    "\n",
    "        for i, (start_char, end_char) in enumerate(offset_mapping):\n",
    "            if start_char <= answer_start < end_char:\n",
    "                start_position = i\n",
    "            if start_char < answer_end <= end_char:\n",
    "                end_position = i\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'start_positions': torch.tensor([start_position], dtype=torch.long),\n",
    "            'end_positions': torch.tensor([end_position], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "class QnADataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data_path, test_data_path, tokenizer):\n",
    "        super().__init__()\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(self.train_data_path)\n",
    "        # train_df = train_df.sample(n=10000, random_state=42, replace=False)\n",
    "\n",
    "        test_df = pd.read_csv(self.test_data_path)\n",
    "        # test_df = test_df.sample(n=2000, random_state=42, replace=False)\n",
    "\n",
    "        self.train_ds = QnADataset(train_df, self.tokenizer)\n",
    "        self.test_ds = QnADataset(test_df, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=4,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )"
   ],
   "id": "f3b11f5587c78dae",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "id": "4516bc289a678454"
   },
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "id": "4516bc289a678454"
  },
  {
   "metadata": {
    "id": "cac3d5343a277f60",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:53:33.976430Z",
     "start_time": "2025-12-10T06:53:33.955073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "\n",
    "class QnAModel(pl.LightningModule):\n",
    "    def __init__(self, model_name='deepset/roberta-base-squad2'):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, start_positions, end_positions):\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions,\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def compute_loss(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        start_positions = batch['start_positions']\n",
    "        end_positions = batch['end_positions']\n",
    "\n",
    "        outputs = self.forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions\n",
    "        )\n",
    "        return outputs.loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('train_loss', loss, prog_bar=True)#â€œRecord the value of loss under the name train_loss.â€\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(params=self.parameters(), lr=5e-5, eps=1e-8)#eps er value ta hocce learning rate er ekta thresold ..j er thek besi choto howar dorkar nai"
   ],
   "id": "cac3d5343a277f60",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "id": "a631687f3d225e27"
   },
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "id": "a631687f3d225e27"
  },
  {
   "metadata": {
    "id": "4aae38563a40a90",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:21:19.893838Z",
     "start_time": "2025-12-10T06:19:26.702460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'deepset/roberta-base-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = QnAModel()\n",
    "ds_module = QnADataModule(\n",
    "    train_data_path=r\"qna_train.csv\",\n",
    "    test_data_path=r\"qna_test.csv\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "id": "4aae38563a40a90",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "id": "6790b955de7f13fe",
    "outputId": "ae12f49e-6e1b-4d7a-a13f-50942114c230",
    "ExecuteTime": {
     "end_time": "2025-12-10T06:53:50.508626Z",
     "start_time": "2025-12-10T06:53:50.393519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1\n",
    ")"
   ],
   "id": "6790b955de7f13fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T15:40:04.020134Z",
     "start_time": "2025-04-19T15:37:25.254025Z"
    },
    "id": "946978bffdd92be6",
    "outputId": "94a887b3-a469-44b8-ce2c-e1c232d8c642",
    "colab": {
     "referenced_widgets": [
      "835bebdea282422a9ea5a9452e019162"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.fit(model, ds_module)"
   ],
   "id": "946978bffdd92be6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "E:\\PyCharmProjects\\venv_manager\\.venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                        | Params | Mode\n",
      "-------------------------------------------------------------\n",
      "0 | model | RobertaForQuestionAnswering | 124 M  | eval\n",
      "-------------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "496.226   Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "227       Modules in eval mode\n",
      "E:\\PyCharmProjects\\venv_manager\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "835bebdea282422a9ea5a9452e019162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "8fdff157bafd58c8"
   },
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "id": "8fdff157bafd58c8"
  },
  {
   "metadata": {
    "id": "88d3ff64f5568c9b",
    "outputId": "c884258c-e0cb-4ada-ba30-8dd4762d9398",
    "colab": {
     "referenced_widgets": [
      "5ed1e247d6cf437eb4414b1d5d2239ef"
     ]
    },
    "ExecuteTime": {
     "end_time": "2025-12-10T06:52:31.902570Z",
     "start_time": "2025-12-10T06:52:23.273078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Zero shot learning: Using a pretrained without any fine-tuning\n",
    "    Few shot learning: We use a smaller subset of our dataset to fine-tune the pretrained model.\n",
    "    Fine tuning: We use custom dataset to train pretrained model.\n",
    "\n",
    "\n",
    "    Result:\n",
    "    Learning             |    test loss\n",
    "    Zero-shot            |    3.45\n",
    "    Few-shot             |    1.26 (500)\n",
    "    Complete Fine-tuning |    1.15 (500)\n",
    "\"\"\"\n",
    "trainer.test(model=model, datamodule=ds_module)"
   ],
   "id": "88d3ff64f5568c9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab3a50c1fe8c488aadc92163ce027653"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "id": "b949f808694ebf78"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "b949f808694ebf78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
