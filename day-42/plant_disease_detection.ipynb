{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2025-12-11T07:02:08.477842Z",
     "start_time": "2025-12-11T07:00:50.320885Z"
    }
   },
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "20c60d79ed15e771",
    "ExecuteTime": {
     "end_time": "2025-12-11T07:02:26.169193Z",
     "start_time": "2025-12-11T07:02:25.967395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = r'F:\\plant disease dataset'\n",
    "df=pd.read_csv(r'F:\\plant disease dataset\\images.csv')\n",
    "df.head()"
   ],
   "id": "20c60d79ed15e771",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filepath             Disease\n",
       "0  F:\\plant disease dataset\\archive\\New Plant Dis...  Apple___Apple_scab\n",
       "1  F:\\plant disease dataset\\archive\\New Plant Dis...  Apple___Apple_scab\n",
       "2  F:\\plant disease dataset\\archive\\New Plant Dis...  Apple___Apple_scab\n",
       "3  F:\\plant disease dataset\\archive\\New Plant Dis...  Apple___Apple_scab\n",
       "4  F:\\plant disease dataset\\archive\\New Plant Dis...  Apple___Apple_scab"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F:\\plant disease dataset\\archive\\New Plant Dis...</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F:\\plant disease dataset\\archive\\New Plant Dis...</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F:\\plant disease dataset\\archive\\New Plant Dis...</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F:\\plant disease dataset\\archive\\New Plant Dis...</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F:\\plant disease dataset\\archive\\New Plant Dis...</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T07:03:00.933670Z",
     "start_time": "2025-12-11T07:03:00.925829Z"
    }
   },
   "cell_type": "code",
   "source": "df.iloc[0]['filepath']",
   "id": "4c31de9caf21907e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\plant disease dataset\\\\archive\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\\\\Apple___Apple_scab\\\\00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T07:03:50.361669Z",
     "start_time": "2025-12-11T07:03:50.352745Z"
    }
   },
   "cell_type": "code",
   "source": "df.iloc[0]['Disease']",
   "id": "325ff75d256fc7dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple___Apple_scab'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "4dbdae010c5a7800",
    "ExecuteTime": {
     "end_time": "2025-12-11T07:07:57.355319Z",
     "start_time": "2025-12-11T07:07:57.349424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.df.iloc[idx]['filepath']}\"\n",
    "\n",
    "        label = self.df.iloc[idx]['Disease']\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label"
   ],
   "id": "dd20548db6fd88cc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "c6ab027bc7303a49",
    "ExecuteTime": {
     "end_time": "2025-12-11T07:14:58.934277Z",
     "start_time": "2025-12-11T07:14:58.919610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CropDiseaseDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),#data augmentation\n",
    "            transforms.RandomRotation(10),#data augmentation<<\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        df = pd.read_csv(r'F:\\plant disease dataset\\images.csv')\n",
    "        df['Disease'] = LabelEncoder().fit_transform(df['Disease'])\n",
    "        num_classes = len(df['Disease'].value_counts())\n",
    "        print(\"Number of classes: {}\".format(num_classes))\n",
    "        train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.train_dataset = CropDiseaseDataset(\n",
    "            train_df,\n",
    "            transform=self.transform\n",
    "        )\n",
    "\n",
    "        self.val_dataset = CropDiseaseDataset(\n",
    "            val_df,\n",
    "            transform=self.transform\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )"
   ],
   "id": "c6ab027bc7303a49",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "f67f1e1a817a2ed3",
    "outputId": "cdb72f68-71f9-4219-c418-6c8e151aacf9",
    "ExecuteTime": {
     "end_time": "2025-12-11T07:15:07.056457Z",
     "start_time": "2025-12-11T07:15:06.375531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_module = CropDiseaseDataModule(\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "data_module.setup()"
   ],
   "id": "f67f1e1a817a2ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 38\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "91ab1d53b53c8d10",
    "ExecuteTime": {
     "end_time": "2025-12-11T08:41:34.516456Z",
     "start_time": "2025-12-11T08:41:34.378630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CropDiseaseClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=38, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32), #means ekta batch e jotogulo image thakbe sobgulo k tader avg and std diye oi image gulo k normalize kore fela\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),#inactive the 50% weights(randomly) on the layer to avoid overfitting\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(#this is learning rate scheduler.This basically does\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=5\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }"
   ],
   "id": "91ab1d53b53c8d10",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "id": "a3465386efc65de1",
    "ExecuteTime": {
     "end_time": "2025-12-11T08:41:58.209952Z",
     "start_time": "2025-12-11T08:41:57.889160Z"
    }
   },
   "cell_type": "code",
   "source": "model = CropDiseaseClassifier(num_classes=38)",
   "id": "a3465386efc65de1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "id": "ce0289522e9c52db",
    "outputId": "7188257f-b2ab-4a53-fcce-02890f1759d5",
    "colab": {
     "referenced_widgets": [
      "9e7ffe18c2314ee9a08c0f71bb299000",
      "4ea385ad0022447d980a5191b8c617be"
     ]
    },
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-12-11T08:47:17.446541100Z",
     "start_time": "2025-12-11T08:42:00.074666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ],
   "id": "ce0289522e9c52db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\u001B[1;35m \u001B[0m\u001B[1;35mName     \u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\u001B[1;35m \u001B[0m\u001B[1;35mType            \u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\u001B[1;35m \u001B[0m\u001B[1;35mFLOPs\u001B[0m\u001B[1;35m \u001B[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0mâ”‚ model     â”‚ Sequential       â”‚ 26.1 M â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0mâ”‚ criterion â”‚ CrossEntropyLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ model     â”‚ Sequential       â”‚ 26.1 M â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ criterion â”‚ CrossEntropyLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 26.1 M                                                                                           \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 26.1 M                                                                                               \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 104                                                                        \n",
       "\u001B[1mModules in train mode\u001B[0m: 23                                                                                          \n",
       "\u001B[1mModules in eval mode\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal FLOPs\u001B[0m: 0                                                                                                     \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 26.1 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 26.1 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 104                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 23                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7705883d5f0541fc91e22ee72862e68a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' \n",
       "does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` \n",
       "to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' \n",
       "does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` \n",
       "to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment \n",
       "analysis)\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\60 days of python\\day-38(Aspect base sentiment analysis)\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6240de97170095cc"
   },
   "cell_type": "code",
   "source": [
    "trainer.validate(model, data_module)"
   ],
   "id": "6240de97170095cc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
